## Benchmarks

My execution of the benchmarks defined in the source [repo](https://github.com/pvillela/rust-latency-trace/tree/main) on my laptop indicates that there is great variability in the latency tracing overhead. With different target functions and different benchmark runs, the overhead per span varied from less than 1 µs up to 23 µs. The overhead percentage relative to the total latency of the uninstrumented version of the target function varied from less than 1% to 7%. Furthermore, given a target function, multiple runs of the same Divan or Criterion bencmark can produce significantly varying results. There was so much variability across runs that sometimes nonsensical negative overheads were observed (i.e., the median total latency of an instrumented function is less than that of the uninstrumented version of the same function). The aforementioned results were for functions that do not make OS calls like thread::sleep() that cause a thread context switch. It appears that thread context switches have a significant adverse impact on overheads, possibly due to the invalidation of processor caches.
